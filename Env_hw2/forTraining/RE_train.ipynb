{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Make DataLoader</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_dir = '.\\\\dataset\\\\training_dataset'\n",
    "test_dir = '.\\\\dataset\\\\validation_dataset'\n",
    "\n",
    "train_transforms = transforms.Compose(  [   transforms.Resize((224,224)),\n",
    "                                            transforms.ToTensor(),                                \n",
    "                                            torchvision.transforms.Normalize(\n",
    "                                                mean=[0.485, 0.456, 0.406],\n",
    "                                                std=[0.229, 0.224, 0.225],\n",
    "                                            ),\n",
    "                                            transforms.RandomErasing()\n",
    "                                        ]   )\n",
    "\n",
    "test_transforms = transforms.Compose(   [   transforms.Resize((224,224)),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize(\n",
    "                                            mean=[0.485, 0.456, 0.406],\n",
    "                                            std=[0.229, 0.224, 0.225],\n",
    "                                            ),\n",
    "                                            transforms.RandomErasing()\n",
    "                                        ]   )\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir,transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(test_dir,transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, shuffle = True, batch_size=32)\n",
    "testloader = torch.utils.data.DataLoader(test_data, shuffle = True, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Making a Training Process</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_process(model, optimizer, loss_func):\n",
    "    \n",
    "    def train_step(x,y):\n",
    "        #make prediction\n",
    "        yhat = model(x)\n",
    "        #enter train mode\n",
    "        model.train()\n",
    "        #compute loss\n",
    "        loss = loss_func(yhat,y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        #optimizer.cleargrads()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Build the ResNet50 Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "resnet50_model = models.resnet50(pretrained=True)\n",
    "\n",
    "#freeze all params\n",
    "for params in resnet50_model.parameters():\n",
    "    params.requires_grad_ = False\n",
    "\n",
    "#add layers in model\n",
    "num_ftrs = resnet50_model.fc.in_features\n",
    "resnet50_model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 1),  # 修改輸出維度為 1，這裡是為了二分類\n",
    "    nn.Sigmoid()  # 加上 Sigmoid 函數\n",
    ")\n",
    "resnet50_model = resnet50_model.to(device)\n",
    "summary(resnet50_model, input_size=(3, 224, 224), device = 'cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Loss, Optimizer, and Train Step</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import BCEWithLogitsLoss\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#loss\n",
    "loss_fn = BCEWithLogitsLoss() #binary cross entropy with sigmoid, so no need to use sigmoid in the model\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(resnet50_model.fc.parameters()) \n",
    "\n",
    "#train step\n",
    "train_step = training_process(resnet50_model, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Train the Model</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to Load model to predict an image is dog or cat?<br>\n",
    "<href>https://blog.csdn.net/qq_41167777/article/details/109013155</href>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "epoch_train_losses = []\n",
    "epoch_test_losses = []\n",
    "\n",
    "n_epochs = 40\n",
    "early_stopping_tolerance = 3\n",
    "early_stopping_threshold = 0.03\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  epoch_loss = 0\n",
    "  for i ,data in tqdm(enumerate(trainloader), total = len(trainloader)): #iterate ove batches\n",
    "    x_batch , y_batch = data\n",
    "    x_batch = x_batch.to(device) #move to gpu\n",
    "    y_batch = y_batch.unsqueeze(1).float() #convert target to same nn output shape\n",
    "    y_batch = y_batch.to(device) #move to gpu\n",
    "\n",
    "\n",
    "    loss = train_step(x_batch, y_batch)\n",
    "    epoch_loss += loss/len(trainloader)\n",
    "    losses.append(loss)\n",
    "    \n",
    "  epoch_train_losses.append(epoch_loss)\n",
    "  print('\\nEpoch : {}, train loss : {}'.format(epoch+1,epoch_loss))\n",
    "\n",
    "  #validation doesnt requires gradient\n",
    "  with torch.no_grad():\n",
    "    cum_loss = 0\n",
    "    for x_batch, y_batch in testloader:\n",
    "      x_batch = x_batch.to(device)\n",
    "      y_batch = y_batch.unsqueeze(1).float() #convert target to same nn output shape\n",
    "      y_batch = y_batch.to(device)\n",
    "\n",
    "      #model to eval mode\n",
    "      resnet50_model.eval()\n",
    "\n",
    "      yhat = resnet50_model(x_batch)\n",
    "      val_loss = loss_fn(yhat,y_batch)\n",
    "      cum_loss += loss/len(testloader)\n",
    "      val_losses.append(val_loss.item())\n",
    "\n",
    "\n",
    "    epoch_test_losses.append(cum_loss)\n",
    "    print('Epoch : {}, val loss : {}'.format(epoch+1,cum_loss))  \n",
    "    \n",
    "    best_loss = min(epoch_test_losses)\n",
    "    \n",
    "    #save best model\n",
    "    if cum_loss <= best_loss:\n",
    "      best_model_wts = resnet50_model.state_dict()\n",
    "    \n",
    "    #early stopping\n",
    "    early_stopping_counter = 0\n",
    "    if cum_loss > best_loss:\n",
    "      early_stopping_counter +=1\n",
    "\n",
    "    if (early_stopping_counter == early_stopping_tolerance) or (best_loss <= early_stopping_threshold):\n",
    "      print(\"/nTerminating: early stopping\")\n",
    "      break #terminate training\n",
    "    \n",
    "#load best model\n",
    "resnet50_model.load_state_dict(best_model_wts)\n",
    "torch.save(resnet50_model, './RE_model.pt')\n",
    "torch.save(best_model_wts, './RE_best_model_wts.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
